{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries and packages:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import csv\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minDim = 80\n",
    "blockSize = (16,16)\n",
    "blockStride = (8,8)\n",
    "cellSize = (8,8)\n",
    "nbins = 9\n",
    "dims = (minDim, minDim)\n",
    "hog = cv2.HOGDescriptor(dims, blockSize, blockStride, cellSize, nbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below section reads all the images from the folder, adds the HOG descriptor information in our dataset.\n",
    "Simultaneously we are also extracting the color of our images and making three new column features R,G,B.\n",
    "Y stores the actual label along with image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2919)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "Y = []\n",
    "R = []\n",
    "G = []\n",
    "B = []\n",
    "for row,i in enumerate(glob.glob(\"V:/user/college/Fall/4660/project/new_images/maskedImages/*.jpg\")):\n",
    "    img_read = cv2.imread(i)\n",
    "    img_label = cv2.resize(img_read, dims) \n",
    "    r=0\n",
    "    g=0\n",
    "    b=0\n",
    "    for k in range(len(img_label)):\n",
    "        for j in range(len(img_label[k])):\n",
    "            r += img_label[k][j][0]\n",
    "            g += img_label[k][j][1]\n",
    "            b += img_label[k][j][2]\n",
    "    R.append(r/6400)\n",
    "    G.append(g/6400)\n",
    "    B.append(b/6400)\n",
    "        \n",
    "    img = cv2.Canny(img_label,750,150)\n",
    "    hist = hog.compute(img)\n",
    "    data.append((hist))\n",
    "    x = os.path.basename(i).split('.')\n",
    "    \n",
    "    if(int(x[0])>=1 and int(x[0])<=100):\n",
    "        Y.append(('Dessert',os.path.basename(i)))\n",
    "    \n",
    "    if(int(x[0])>=101 and int(x[0])<=200):\n",
    "        Y.append(('Entree',os.path.basename(i)))\n",
    "    \n",
    "    if(int(x[0])>=201 and int(x[0])<=300):\n",
    "         Y.append(('Salad',os.path.basename(i)))\n",
    "\n",
    "data = np.reshape(data,(300,2916))            \n",
    "\n",
    "new_list = []\n",
    "for i in range(len(data)):\n",
    "    a = list(data[i])\n",
    "    a.append(R[i])\n",
    "    a.append(G[i])\n",
    "    a.append(B[i])\n",
    "    new_list.append(a)\n",
    "data = new_list\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the K_means algorithm and storing the retrived lables in another list 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_KMeans = KMeans(n_clusters=3)\n",
    "my_KMeans.fit(data)\n",
    "labels = my_KMeans.labels_\n",
    "labels\n",
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding the retrieved labels into existing list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for i in range(len(Y)):\n",
    "    a = list(Y[i])\n",
    "    a.append(my_KMeans.labels_[i])\n",
    "    new_list.append(a)\n",
    "Y = new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are checking which image has been put into which cluster and printing the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entree0: 71\n",
      "entree1: 22\n",
      "entree2: 7\n",
      "salad0: 18\n",
      "salad1: 19\n",
      "salad2: 63\n",
      "dessert0: 30\n",
      "dessert1: 69\n",
      "dessert2: 1\n",
      "total: 300\n"
     ]
    }
   ],
   "source": [
    "entree1 = 0\n",
    "entree2 = 0\n",
    "entree0 = 0\n",
    "salad1 = 0\n",
    "salad2 = 0\n",
    "salad0 = 0\n",
    "dessert1 = 0\n",
    "dessert2 = 0\n",
    "dessert0 = 0\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    if(Y[i][0] == \"Entree\" and Y[i][2] == 0):\n",
    "        entree0 +=1\n",
    "    if(Y[i][0] == \"Entree\" and Y[i][2] == 1):\n",
    "        entree1 +=1\n",
    "    if(Y[i][0] == \"Entree\" and Y[i][2] == 2):\n",
    "        entree2 +=1\n",
    "    if(Y[i][0] == \"Salad\" and Y[i][2] == 0):\n",
    "        salad0 +=1\n",
    "    if(Y[i][0] == \"Salad\" and Y[i][2] == 1):\n",
    "        salad1 +=1\n",
    "    if(Y[i][0] == \"Salad\" and Y[i][2] == 2):\n",
    "        salad2 +=1\n",
    "    if(Y[i][0] == \"Dessert\" and Y[i][2] == 0):\n",
    "        dessert0 +=1\n",
    "    if(Y[i][0] == \"Dessert\" and Y[i][2] == 1):\n",
    "        dessert1 +=1\n",
    "    if(Y[i][0] == \"Dessert\" and Y[i][2] == 2):\n",
    "        dessert2 +=1\n",
    "        \n",
    "print(\"entree0:\",entree0)\n",
    "print(\"entree1:\",entree1)\n",
    "print(\"entree2:\",entree2)\n",
    "print(\"salad0:\",salad0)\n",
    "print(\"salad1:\",salad1)\n",
    "print(\"salad2:\",salad2)\n",
    "print(\"dessert0:\",dessert0)\n",
    "print(\"dessert1:\",dessert1)\n",
    "print(\"dessert2:\",dessert2)\n",
    "a = entree0 + entree1 +entree2 +salad0 +salad1 +salad2 +dessert0 + dessert1 + dessert2\n",
    "print(\"total:\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying SVM algorithm on our dataset with the labels we have found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy  0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=2)\n",
    "lsvm = SVC(kernel='linear', C = 1.0, probability=True)\n",
    "lsvm.fit(X_train, y_train)\n",
    "print(\"test accuracy \", lsvm.score(X_test, y_test))\n",
    "y_pred = lsvm.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_thresholding(image):\n",
    "    img = cv2.imread(image)\n",
    "    img2gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret,mask = cv2.threshold(img2gray,200,255,cv2.THRESH_BINARY_INV)\n",
    "    img_fg = cv2.bitwise_and(img,img,mask =mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the below function returns an image by applying binary thresholding on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resizing_image(image):\n",
    "    resized_image = cv2.resize(img_read, dims) \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resizing the image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
